---
title: "New College of Florida - Allen Institute Project"
output: html_document
editor_options: 
  chunk_output_type: console
---

##### *Manda Bucklin*
##### *Andrew Reilly*
##### *Nate Wagner*

<br>



```{r message=FALSE, warning=FALSE, include=FALSE}
library(plotly)
library(keras)
library(tidyverse)
library(reshape)
library(MASS)
library(ggforce)
library(beeswarm)
library(ggplot2)
library(wesanderson)
library(gridExtra)
library(pheatmap)
library(RColorBrewer)
library(colorspace)
#library(R.utils)
library(stringr)
library(superheat)
#library(sm)
#library(vioplot) 
library(umap)
np_gpcr_cpm=as.data.frame(read.csv("np_gpcr_cpm.csv"))
```


```{r message=FALSE, warning=FALSE, include=FALSE}

#NPP
nppm <- c("Npy","Sst","Vip","Tac2", "Cck","Penk","Crh","Cort", "Tac1", "Pdyn", "Pthlh", "Pnoc","Trh","Grp","Rln1","Adcyap1","Nts","Nmb")
npph <- toupper(nppm)
# NP-GPCR
npgpcrm <- c("Sstr2", "Npy2r", "Npy1r", "Grpr", "Cckbr", "Ntsr2", "Npy5r", "Nmbr", "Rxfp1", "Sstr4",
          "Trhr","Sstr1","Adcyap1r1","Crhr1","Rxfp3","Oprl1","Crhr2","Tacr3","Oprk1","Tacr1",
          "Pth1r","Vipr1","Oprm1","Trhr2","Vipr2","Rxfp2","Oprd1","Ntsr1","Sstr3")
npgpcre <- c("Npy1r","Npy2r","Npy5r","Sstr1","Sstr2","Sstr3","Sstr4","Sstr5","Adcyap1r1","Vipr1","Vipr2",
          "Tacr2","Tacr3","Cckbr","Oprd1", "Oprm1", "Crhr1", "Crhr2", "Tacr1", "Oprk1", "Pth1r", "Oprl1",
          "Trhr", "Trhr2", "Grpr", "Rxfp1", "Rxfp2", "Rxfp3", "Calcrl", "Ednrb", "Galr1", "Ntsr1", "Ntsr2",
          "Nmbr", "Npbwr1", "Npffr1", "Agtr1a", "Agtr2", "Prokr2", "Mc1r", "Mc3r", "Mc4r", "Mc5r", "Avpr1a",
          "Hcrtr1", "Hcrtr2", "Nmur1", "Kiss1r", "Uts2r", "Gcgr", "Glp1r", "Glp2r", "Tshr", "Pth2r", "Oxtr",
          "Ghrhr","Mchr1","Gipr","Npsr1")
```



```{r echo=FALSE, message=FALSE, warning=FALSE}
d1=subset(np_gpcr_cpm,class_label=="GABAergic",nppm)
cvec=sum(apply(d1,1,sum)>0)
totcell=dim(d1)[1]
bimat=d1>0
almcnt=c(1,cvec/totcell,apply(bimat,2,sum)/totcell)
b1=almcnt[-1]
names(almcnt)[1]="GABAergic"
names(b1)[1]="Any NP-GPCR"
pervec_alm=almcnt[c(-1,-2)]
d1=subset(np_gpcr_cpm,class_label=="Glutamatergic",nppm)
cvec=sum(apply(d1,1,sum)>0)
totcell=dim(d1)[1]
bimat=d1>0
almcnt=c(1,cvec/totcell,apply(bimat,2,sum)/totcell)
b2=almcnt[-1]
names(almcnt)[1]="GABAergic"
names(almcnt)[2]="Any NP-GPCR"
names(b1)[1]="Any NP-GPCR"
pervec_alm=almcnt[c(-1,-2)]
d1=subset(np_gpcr_cpm,class_label=="Non-Neuronal",nppm)
cvec=sum(apply(d1,1,sum)>0)
totcell=dim(d1)[1]
bimat=d1>0
almcnt=c(1,cvec/totcell,apply(bimat,2,sum)/totcell)
b3=almcnt[-1]
names(almcnt)[1]="Non-Neuronal"
#names(almcnt)[2]="Any NPP"
#names(b1)[1]="Any NPP"
pervec_alm=almcnt[c(-1,-2)]
# dual plot
c1=rbind(b1,b2, b3)
row.names(c1)=c("GABAergic","Glutamatergic", "Non-Neuronal")
cr1=rainbow_hcl(19)[5]
cr2=rainbow_hcl(19)[13]
cr3=rainbow_hcl(19)[1]
par(las=2)
barplot(c1,col=rbind(rep(cr1,14),rep(cr2,14), rep(cr3,14)),ylim=c(0,1),beside=TRUE,main="NPP Expressing Cells - GABAergic, Non-Neuronal, & Glutamatergic")
legend(50,0.8,legend=c("GABAergic","Glutamatergic", "Non-Neuronal"),col=c(cr1,cr2, cr3),pch=c(15,15),box.lty=0,pt.cex=1.5,cex=1.25)

```


<br>


```{r echo=FALSE, message=FALSE, warning=FALSE}
d1=subset(np_gpcr_cpm,class_label=="GABAergic",npgpcrm)
cvec=sum(apply(d1,1,sum)>0)
totcell=dim(d1)[1]
bimat=d1>0
almcnt=c(1,cvec/totcell,apply(bimat,2,sum)/totcell)
b1=almcnt[-1]
names(almcnt)[1]="GABAergic"
names(b1)[1]="Any NP-GPCR"
pervec_alm=almcnt[c(-1,-2)]
d1=subset(np_gpcr_cpm,class_label=="Glutamatergic",npgpcrm)
cvec=sum(apply(d1,1,sum)>0)
totcell=dim(d1)[1]
bimat=d1>0
almcnt=c(1,cvec/totcell,apply(bimat,2,sum)/totcell)
b2=almcnt[-1]
names(almcnt)[1]="GABAergic"
names(almcnt)[2]="Any NP-GPCR"
names(b1)[1]="Any NP-GPCR"
pervec_alm=almcnt[c(-1,-2)]
d1=subset(np_gpcr_cpm,class_label=="Non-Neuronal",npgpcrm)
cvec=sum(apply(d1,1,sum)>0)
totcell=dim(d1)[1]
bimat=d1>0
almcnt=c(1,cvec/totcell,apply(bimat,2,sum)/totcell)
b3=almcnt[-1]
names(almcnt)[1]="Non-Neuronal"
#names(almcnt)[2]="Any NP-GPCR"
#names(b1)[1]="Any NP-GPCR"
pervec_alm=almcnt[c(-1,-2)]
# dual plot
c1=rbind(b1,b2, b3)
row.names(c1)=c("GABAergic","Glutamatergic", "Non-Neuronal")
cr1=rainbow_hcl(19)[5]
cr2=rainbow_hcl(19)[13]
cr3=rainbow_hcl(19)[1]
par(las=2)
barplot(c1,col=rbind(rep(cr1,14),rep(cr2,14), rep(cr3,14)),ylim=c(0,1),beside=TRUE,main="NP-GPCR Expressing Cells - GABAergic, Glutamatergic, & Non-Neuronal")
legend(70,0.8,legend=c("GABAergic","Glutamatergic", "Non-Neuronal"),col=c(cr1,cr2, cr3),pch=c(15,15),box.lty=0,pt.cex=1.5,cex=1.25)

```



<br>


### NPP
```{r message=FALSE, warning=FALSE, include=FALSE}
namesNPP <- c("Vip","Npy","Sst","Cck","Tac2","Crh","Penk","Tac1","Pdyn","Cort","Pthlh","Cartpt","Pnoc","Nmb","Trh","Adcyap1","Grp","Nts","Rln1")

# extract Npp data & convert to matrix
NppData <- np_gpcr_cpm[namesNPP]
NppDataM <- as.matrix(NppData)

# normalize data
range01 <- function(x){
  (x-min(x))/(max(x)-min(x))
  }
NppDataM <- apply(NppDataM, 2, range01)

## 60% of the sample size
smp_size <- floor(0.6 * nrow(NppDataM))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(NppDataM)), size = smp_size)
x_train <- NppDataM[train_ind, ]
x_test <- NppDataM[-train_ind, ]

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# SVD
sv <- svd(NppData)
PC1 <- as.data.frame(sv$u[, 1])
PC2 <- as.data.frame(sv$u[, 2])
labels <- as.data.frame(np_gpcr_cpm$class_label)
SV.Npp <- cbind(PC1, PC2)
SV.Npp <- cbind(SV.Npp, labels) 
names(SV.Npp) <- c('PC1', 'PC2', 'labels') 

plot1 <- ggplot(SV.Npp, aes(PC1, PC2, col = labels)) + geom_point() + labs(title = "NPP")#+ theme(legend.position = "none")
ggplotly(plot1)
```

```{r message=FALSE, warning=FALSE}
# PCA
pc <- prcomp(NppDataM)
PC1 <- as.data.frame(pc$x[, 1])
PC2 <- as.data.frame(pc$x[, 2])
PC.Npp <- cbind(PC1, PC2)
PC.Npp <- cbind(PC.Npp, labels) 
names(PC.Npp) <- c('PC1', 'PC2', 'labels') 

plot2 <- ggplot(PC.Npp, aes(PC1, PC2, col = labels)) + geom_point() + labs(title = "NPP")#+ theme(legend.position = "none")
plot2
```
<br>

### Autoencoder for Dimension Reduction

```{r message=FALSE, warning=FALSE}
#x_train <- x_test <- NppDataM
library(keras)
K <- keras::backend()
## Deep learning model
input_size <- ncol(x_train) ## 1000 genes
hidden_size <- 10 ## 10 dimensional hidden layer
code_size <- 2 ## 2 dimensional encoding
input <- layer_input(shape=c(input_size))
hidden_1 <- layer_dense(input, hidden_size) %>% 
  layer_activation_leaky_relu() %>%
  layer_dropout(rate=0.1)
code <- layer_dense(hidden_1, code_size) %>% 
  layer_activation_leaky_relu()
hidden_2 <- layer_dense(code, units=hidden_size) %>% 
  layer_activation_leaky_relu()
output <- layer_dense(hidden_2, units=input_size, activation="sigmoid")


## input and output should be the same
autoencoder <- keras_model(input, output)
## encoder from input to code space
encoder <- keras_model(input, code)

## Learn
autoencoder  %>% compile(optimizer='adam', 
                         loss='categorical_crossentropy',
                         metrics='mae')
autoencoder %>% fit(
  x_train, x_train, 
  shuffle=TRUE, 
  epochs=50, 
  batch_size=100, 
  validation_data=list(x_test, x_test)
)

## predict code space using deep learning  model
x_test_encoded <- predict(encoder, 
                          x_test, 
                          batch_size=100)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
############### Plot
emb2 <- as.data.frame(x_test_encoded)
names(emb2) <- c('PC1', 'PC2') 
labels_m <- as.matrix(np_gpcr_cpm$class_label)
labels_t <- labels_m[-train_ind, ]
labels <- as.character(labels_t)
emb2 <- cbind(emb2, labels)

ggplot(emb2, aes(PC1, PC2, col = labels)) + geom_point() + labs(title = "NPP")#+ theme(legend.position = "none")
```

<br>

### NP-GPCR

<br>

```{r echo=FALSE, message=FALSE, warning=FALSE}
namesGPCR <- c("Vipr1","Vipr2","Npy1r","Npy2r","Npy4r","Npy5r","Sstr1","Sstr2","Sstr3","Sstr4","Cckbr","Tacr3","Crhr1","Crhr2","Oprd1","Oprm1","Tacr1","Oprk1","Pth1r","Oprl1","Nmbr","Trhr","Trhr2","Adcyap1r1","Grpr","Ntsr1","Ntsr2","Rxfp1","Rxfp2","Rxfp3")

# extract Npp data & convert to matrix
NppData <- np_gpcr_cpm[namesGPCR]
NppDataM <- as.matrix(NppData)

# normalize data
range01 <- function(x){
  (x-min(x))/(max(x)-min(x))
  }
NppDataM <- apply(NppDataM, 2, range01)

## 60% of the sample size
smp_size <- floor(0.6 * nrow(NppDataM))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(NppDataM)), size = smp_size)
x_train <- NppDataM[train_ind, ]
x_test <- NppDataM[-train_ind, ]

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# SVD
sv <- svd(NppData)
PC1 <- as.data.frame(sv$u[, 1])
PC2 <- as.data.frame(sv$u[, 2])
labels <- as.data.frame(np_gpcr_cpm$class_label)
SV.Npp <- cbind(PC1, PC2)
SV.Npp <- cbind(SV.Npp, labels) 
names(SV.Npp) <- c('PC1', 'PC2', 'labels') 

plot1 <- ggplot(SV.Npp, aes(PC1, PC2, col = labels)) + geom_point() + labs(title = "NP-GPCR") #+ theme(legend.position = "none")
ggplotly(plot1)
```
 
```{r echo=FALSE, message=FALSE, warning=FALSE}
# PCA
pc <- prcomp(NppDataM)
PC1 <- as.data.frame(pc$x[, 1])
PC2 <- as.data.frame(pc$x[, 2])
PC.Npp <- cbind(PC1, PC2)
PC.Npp <- cbind(SV.Npp, labels) 
names(PC.Npp) <- c('PC1', 'PC2', 'labels') 

plot2 <- ggplot(PC.Npp, aes(PC1, PC2, col = labels)) + geom_point() + labs(title = "NP-GPCR")
plot2
```

<br>

### Autoencoder for Dimension Reduction

```{r echo=FALSE, message=FALSE, warning=FALSE}
#x_train <- x_test <- NppDataM
library(keras)
K <- keras::backend()
## Deep learning model
input_size <- ncol(x_train) ## 1000 genes
hidden_size <- 10 ## 5 dimensional hidden layer
code_size <- 2 ## 2 dimensional encoding
input <- layer_input(shape=c(input_size))
hidden_1 <- layer_dense(input, hidden_size) %>% 
  layer_activation_leaky_relu() %>%
  layer_dropout(rate=0.1)
code <- layer_dense(hidden_1, code_size) %>% 
  layer_activation_leaky_relu()
hidden_2 <- layer_dense(code, units=hidden_size) %>% 
  layer_activation_leaky_relu()
output <- layer_dense(hidden_2, units=input_size, activation="sigmoid")


## input and output should be the same
autoencoder <- keras_model(input, output)
## encoder from input to code space
encoder <- keras_model(input, code)

## Learn
autoencoder %>% compile(optimizer='adam', 
                         loss='categorical_crossentropy',
                         metrics='mae')
autoencoder %>% fit(
  x_train, x_train, 
  shuffle=TRUE, 
  epochs=50, 
  batch_size=100, 
  validation_data=list(x_test, x_test)
)

## predict code space using deep learning  model
x_test_encoded <- predict(encoder, 
                          x_test, 
                          batch_size=100)

```

```{r echo=FALSE}
############### Plot
emb2 <- as.data.frame(x_test_encoded)
names(emb2) <- c('PC1', 'PC2') 
labels_m <- as.matrix(np_gpcr_cpm$class_label)
labels_t <- labels_m[-train_ind, ]
labels <- as.character(labels_t)
emb2 <- cbind(emb2, labels)

ggplot(emb2, aes(PC1, PC2, col = labels)) + geom_point() + labs(title = "NP-GPCR")
```

<br>
<br>

### Autoencoder - Reduced to Three Dimensions

```{r echo=FALSE, message=FALSE, warning=FALSE}
#x_train <- x_test <- NppDataM
library(keras)
K <- keras::backend()
## Deep learning model
input_size <- ncol(x_train) ## 1000 genes
hidden_size <- 10 ## 5 dimensional hidden layer
code_size <- 3 ## 2 dimensional encoding
input <- layer_input(shape=c(input_size))
hidden_1 <- layer_dense(input, hidden_size) %>% 
  layer_activation_leaky_relu() %>%
  layer_dropout(rate=0.1)
code <- layer_dense(hidden_1, code_size) %>% 
  layer_activation_leaky_relu()
hidden_2 <- layer_dense(code, units=hidden_size) %>% 
  layer_activation_leaky_relu()
output <- layer_dense(hidden_2, units=input_size, activation="sigmoid")


## input and output should be the same
autoencoder <- keras_model(input, output)
## encoder from input to code space
encoder <- keras_model(input, code)

## Learn
autoencoder %>% compile(optimizer='adam', 
                         loss='categorical_crossentropy',
                         metrics='mae')
autoencoder %>% fit(
  x_train, x_train, 
  shuffle=TRUE, 
  epochs=50, 
  batch_size=100, 
  validation_data=list(x_test, x_test)
)

## predict code space using deep learning  model
x_test_encoded <- predict(encoder, 
                          x_test, 
                          batch_size=100)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
############### Plot
emb2 <- as.data.frame(x_test_encoded)
names(emb2) <- c('PC1', 'PC2', 'PC3') 
labels_m <- as.matrix(np_gpcr_cpm$class_label)
labels_t <- labels_m[-train_ind, ]
labels <- as.character(labels_t)
emb2 <- cbind(emb2, labels)

plot_ly(as.data.frame(emb2), x=~PC1, y=~PC2, z=~PC3, mode= "markers",type = "scatter3d",color=~labels_t)
```

<br>
<br>
